\documentclass[a4paper]{article}
\usepackage{hyperref}
\usepackage{fullpage} % Package to use full page
\usepackage{tikz} % Package for drawing

\usepackage{fancyhdr, graphicx, amssymb}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\include{pythonlisting}

\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{fancyvrb}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[bottom]{footmisc}
\usepackage{titling}
\usepackage[margin=0.6in]{geometry}
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{0.5\baselineskip}{0.3\baselineskip}
\titlespacing*{\subsection}{0pt}{0.5\baselineskip}{0.3\baselineskip}

\hypersetup{
    colorlinks=true, 
    urlcolor=blue
}

\setlength{\droptitle}{-8em}   % This is your set screw
\begin{document}



\section{Scoring Function Overview}
The scoring function that I have designed builds upon the suggestions in the assignment brief, and to the best of my knowledge has strong biological intuition. The score function is made up of three key parts. 
\subsection{Convex Gap Scores}
It is well-known that single mutation events - such as translocation and duplication - may create alignment gaps of different sizes. Therefore, there is a biological need to treat such gaps as a single entity, as opposed to individually penalising each successive \textit{indel}. Two protein sequences may be relatively similar but differ only at a certain interval, and we don't want to excessively penalise such an alignment. Affine gap scores have been used extensively in industry, and are often the gap score method of choice when partnered with the \textit{BLOSUM} score matrices. An affine gap score combines a constant 'gap-opening' penalty (favouring shorter gaps) with an additional penalty that is linear in the number of further residues in the gap (favouring fewer, larger gaps). Typically, the 'gap-opening' penalty is an order of magnitude larger than the additional penalty ((10, 1) for BLOSUM-62), and thus such a gap-score scheme goes some way to reducing the penalty given to large gaps. However, it has been shown empirically that an affine gap length is too rigid for use in a biological context\footnote{Sung, Wing-Kin (2011). \textit{Algorithms in Bioinformatics : A Practical Introduction. CRC Press. pp. 42?47}}. Moreover, other studies have shown that the distribution of \textit{indels} typically follows a power law (logarithmic) distribution\footnote{\url{http://elbo.gs.washington.edu/courses/GS_559_11_wi/slides/4A-Sequence_comparison-ScoreMatrices.pdf}}. Therefore, I have opted to use a convex gap penalty model, in which each additional space in a gap contributes less to the gap weight than the previous space. The model I propose for (internal) gap scores is:
\begin{center}
$P_g \cdot \ln(n) $
\end {center}
where $P_g$ is the gap opening penalty, and $n$ is the length of the gap. 

\subsection{Trailing, Internal and Terminating Gap Score Differentiation}
The second key feature of my scoring function is the implementation of different gap-scoring parameters for trailing, internal, and terminating gaps. It has been shown empirically, through optimization techniques, that the optimal model for matches often has opening and terminal gap-open penalties that are approximately half of the gap-open penalty used for internal gaps\footnote{\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC548345/}}. Intuitively, this makes sense - the query sequence could merely be a translation of the database sequence, and should not be excessively penalised. Therefore, the model I propose for trailing and terminating gap sequences is:
\begin{center}
$\frac{P_g}{2} \cdot \ln(n) $
\end {center}
where $P_g$ is the gap opening penalty, and $n$ is the length of the gap.
 It is worth noting that this feature of the scoring function only applies to the global alignment case, as all (biologically-imitating) score functions assign negative scores to gaps, and so leading and trailing gaps would never be included in a local alignment. 
 
\subsection{Codon Match Reward}
A codon is a set of three bases (technically three nucelotides) which codes for a certain amino acid. This sequence of contiguous triplets defines a protein's functionality, and the codons hold the key to the translation of genetic information for the synthesis of proteins. Therefore, I believe matches of (multiples of) three contiguous bases should be rewarded with a score that is higher than the summation of the scores of the individual matches. I propose a multiplicative scoring system, where:
\begin{center}
$Adjusted\;Score = C(t) \cdot Additive\;Score $,
\end {center}
where $t$ is the number of codons matched consecutively. This codon scoring scheme could be extend further and the entire alignment scoring could be implemented on the codon level, using the empirical scoring matrices found here\footnote{\url{https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-6-134}}.

\subsection{Further Features}
Further features that could be included to more accurately mimic biologically reality include:
\begin{itemize}
\item Take into account the position within the current codon. Point mutation frequencies are not evenly distributed over the three positions within a codon, so different scoring matrices could be used for each of the three positions
\item Have gap-specific indel scores. There is evidence to suggest that specific residue types are preferred in gap regions\footnote{Wrabl JO, Grishin NV (2004). "Gaps in structurally similar proteins: towards improvement of multiple sequence alignment" }, and so once a gap has been opened a secondary scoring matrix could be used for the following residues in the gap.
\item Score specific mutation events individually. For example, in the case of a duplicated amino acid (a triplet/codon of three bases), the penalty induced for the insertion of three \textit{indels} could be reduced if the three residues are identical to previous triplet of residues: as in the case of AAC\textbf{ACG}TCG and AAC\textbf{ACGACG}TCG, for example. 

\end{itemize}

\section{Scoring Function Implementation}
\subsection{Parameters}
As I have described an array of different features above, I shall implement only the convex gap score penalty, and the codon match reward function. The parameters required are therefore:
\begin{itemize}
\item The gap-opening penalty: $P_g = -10$ (as is often used with some of the BLOSUM matrices)
\item The codon match reward function: $ C(t) = \begin{cases} 
      1 + (0.1)t & 0 \leq t \leq 10 \\
      2 & t > 10 \\
      \end{cases} $ where $t = \lfloor{m/3}\rfloor$, and $m$ is the number of contiguously matched residues. This function increasingly rewards longer contiguous matches of codons. 
\item The scoring matrix: $a =  \bigl( \begin{smallmatrix}1 & -1 & -2\\ -1 & 2 & -4\\ -2 & -4 & 3\end{smallmatrix}\bigr)$, indexed in the usual way for the alphabet $\Sigma = \{A, B, C\}$. In the absence of a real scoring matrix such as PAM or BLOSUM, I shall use the score matrix given in the assignment brief. In reality, the score matrix would be alphabet-specific, and would be found empirically using the probabilistic model discussed in lectures. 

\end{itemize}
\subsection{Algorithm}

\begin{algorithm}[H]
\SetAlgoLined
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}

\Input{A query sequence $Q$, and a database sequence $D$, both formed from the alphabet $\Sigma = \{A, B, C\}$}
\Output{An array of [Alignment Score, The indices of $Q$, The indices of $D$]}
\KwData{\\
score\_matrix $\leftarrow [[1, -1, -2], [-1, 2, -4], [-2, -4, 3]]$\\
$P_g \leftarrow -4$\\
$C(t) \leftarrow 1 + (0.1 \cdot t) \: if \; 0 \leq t \leq 10 \: else \; 2$

}
\BlankLine
 $align\_matrix \leftarrow$ zero\_array($m + 1, n + 1$)\;
 $pointers \leftarrow$ zero\_array($m + 1, n + 1$)\;
 \BlankLine
 \For{i, l in enumerate(D)}{
 	\For{j, k in enumerate(Q)}{
		$left\_gap, a, b \leftarrow$ backtrack($i, j, left$)\;
		$up\_gap, c, d \leftarrow$ backtrack($i, j, up$)\;
		$diag\_gap \leftarrow$ backtrack($i, j, diag$)\;
		\BlankLine
		$left\_score \leftarrow align\_matrix[a, b] + (P_g \cdot \ln(left\_gap + 2))$\;
		$up\_score \leftarrow align\_matrix[c, d] + (P_g \cdot \ln(up\_gap + 2))$\;
		$diag\_score \leftarrow align\_matrix[i, j] + (score\_matrix[l, k] \; \cdot \; $C($\lfloor{\frac{diag\_gap}{3}}\rfloor$)\;
		\BlankLine
		$scores \leftarrow$ array($0, left\_score, diag\_score, up\_score$)\;
		$align\_matrx[i + 1, j + 1] \leftarrow $ max($scores$)\;
		$pointers[i + 1, j + 1] \leftarrow $ argmax($scores$)\;
		
	}
 }
 \While{While condition}{
  instructions $]\leftarrow test$\;
  \eIf{condition}{
   instructions1\;
   }{
   instructions3\;
  }
 }

 \caption{Local Sequence Alignment with Convex Gap Penalties and Codon Rewards}
\end{algorithm}

A few small prerequisites need to be installed before running my program. These are: Python 3, GNU Multiple Precision Arithmetic Library (GMP), and the SoPlex solver. I shall include the GMP and SoPlex archived files (for installation on a Unix-based system) in my final submission. Alternatively, follow the blue links to go to their respective download pages. To install these dependencies, please follow the instructions below:

\begin{itemize}
\item \textbf{\href{https://gmplib.org/}{GNU Multiple Precision Arithmetic Library}} \\ Please change directory to where the \textit{gmp-6.1.2.tar.lz} file is located and run the following commands:
\begin{center}
\begin{minipage}{4cm}
\begin{Verbatim}[numbers=left, numberblanklines=false]
lzip -d gmp-6.1.2.tar.lz
tar -xf gmp-6.1.2.tar
cd gmp-6.1.2
./configure
make
make check
make install
\end{Verbatim}
\end{minipage}
\end{center}

\item \textbf{\href{https://soplex.zib.de/index.php\#download}{SoPlex Solver}} \\ Please change directory to where the \textit{soplex-4.0.1.tgz} file is located and run the following commands:
\begin{center}
\begin{minipage}{4cm}
\begin{Verbatim}[numbers=left, numberblanklines=false]
tar -xf soplex-4.0.1.tgz
cd soplex-4.0.1
mkdir build
cd build
cmake <path/to/SoPlex> -DGMP=true
make
make test
make install
\end{Verbatim}
\end{minipage}
\end{center}

\item \textbf{\href{http://www.pyomo.org/installation}{Pyomo}} \\ The easiest way to install Pyomo is to use Python's built-in package manager, \textit{pip}. Once \textit{pip} has been installed, please run the following command:
\begin{center}
\begin{minipage}{4cm}
\begin{Verbatim}[numbers=left, numberblanklines=false]
pip install pyomo
\end{Verbatim}
\end{minipage}
\end{center}
\end{itemize}

Should you run into any issues installing any of these dependencies, please consult the relevant INSTALL files and documentation.

\section{Usage}
\subsection{Directory Structure}
Once the dependencies have been installed, the directory structure should look something like Figure 1 (varying slightly if you installed the dependencies in a different location):

\textbf{Note}: The program will \textbf{not} work unless the four folders (\textit{graphs}, \textit{models}, \textit{settings}, \textit{solutions}) are present. This is what is contained in each folder:
\begin{itemize}
\item \textbf{/graphs}: This folder contains the input graph files. Graph files should be saved with a \textit{.txt} extension, and follow the following format:
\begin{center}
\centering
\begin{BVerbatim}
[V] [E]
[v11] [v12]
[v21] [v22]
 ...
[vE1] [vE2]
\end{BVerbatim}
\end{center}  
where \textbf{V} is the number of vertices, \textbf{E} is the number of edges, and each \textbf{[vi1] [vi2]} pair (for i $\in$ \{1, 2, ... , E\} represents the edge between vertex \textbf{[vi1]} and \textbf{[vi2]}. For example, the complete four-vertex graph would be represented as follows:
\begin{center}
\centering
\begin{BVerbatim}
4 6
0 1
0 2
0 3
1 2
1 3
2 3
\end{BVerbatim}
\end{center} 
\textbf{Note}: Vertex numbering \textit{must} start at 0, not 1, for the program to work. 
\item \textbf{/models}: This folder contains the \textit{.mps} linear program modelling files generated by my program, which are then solved by the SoPlex solver. 
\item \textbf{/settings}: This folder contains the settings files for the SoPlex solver.
\item \textbf{/solutions}: This folder contains the detailed solutions outputted by the SoPlex solver. Each time the program is executed, it will output two files - one for the Fractional Clique Cover Number, and one for the Shannon Entropy. 
\end{itemize}
\subsection{Running}
To run the program, please run the following command (from the base directory):
\begin{center}
\centering
\begin{BVerbatim}
python Assignment.py graphs/[graphName.txt] 
\end{BVerbatim}
\end{center}
The program will output the Fractional Clique Cover Number, the Shannon Entropy, and the solutions to both of the linear programs concisely, and in rational format. As mentioned above, more detailed output for both linear programs is saved in the /solutions folder.        

\section{Linear Program Reformulation}                                                                                                                                                                                                                                                                                         
\subsection{Fractional Clique Cover Number}
\begin{itemize}
\item In the specification, variables are introduced for all the subsets $S$ of $V$, the set of all vertices. However, as the only non-zero variables are those corresponding to the cliques of $V$, I introduced variables only for the cliques. To find the cliques of $V$ efficiently, I modified the well-known \textit{Bron Kerbosch} algorithm, so that it recursively finds \textit{all} the cliques of $V$, not only the maximal ones. 
\item Whilst searching for how to further simplify the linear program, I found an article by Peter Cameron\cite{Article} which states that \textit{"It can be shown that the same minimum value [the Fractional Clique Cover Number] is obtained if we restrict to regular fractional clique covers.}". A regular fractional clique cover is one where, for every vertex, the sum of the values given to the cliques that contain this vertex \textbf{equals} one, rather than being bounded above by 1. The proof of this claim can be found in the paper referenced in the article\cite{Paper}, and so I implemented this simplification in my program.
\end{itemize}

\subsection{Shannon Entropy}
For the Shannon Entropy linear program, variables are required for all of the subsets of the set of vertices V. However, many of the constraints 'overlap' and so are redundant.
\begin{itemize}
\item The first constraint that I simplified was the:
\begin{center}
$x_T - x_S \geq 0 \quad \forall S \subseteq T \subseteq V$
\end {center}
constraint. For very subset $T$ of $V$, we do not need to create a constraint for every subset S of T; it is sufficient to only create constraints for subsets $S$ that are of size one less than $T$. This is because if $R \subseteq S \subseteq T$, then $x_R \leq x_S$ and $x_S \leq x_T \implies x_R \leq x_T$. This is more easily shown diagramatically:

For a graph of N vertices, the total number of constraints without the reformulation would be $\sum_{n=2}^N \binom{N}{n}(2^n - 1)$ (where constraints involving the empty set have been removed as the variable corresponding to the empty set is 0), whereas the the number of constraints with this reformulation is $\sum_{n=2}^N \binom{N}{n}n$. For the N = 8 case, this is a reduction of $6297 - 1016 = 5281$ constraints.
\item To increase the efficiency of the constraint generation, I calculated the above constraint and the $X_{N(v) \cup \{v\}} - x_{N(v)} = 0$ constraint in one traversal of the subsets pairs, as the neighbourhood constraint also involves two sets differing in size by only one variable. I don't think it is possible to further simplify the neighbourhood constraint, and as there is only one constraint per vertex, the number of these constraints is negligible with respect to the total number of constraints. 
\item The next constraint that I simplified significantly was the:
\begin{center}
$x_S + x_T - x_{S\cup T} - x_{S\cap T} \geq 0 \quad \forall S, T \subseteq V$
\end{center}
constraint. Instead of creating a constraint for every pair of vertices $S$ and $T$, of which there would be $2^N \times 2^N = 2^{2N}$, constraints are only required for pairs of vertices where $S \not\subseteq T$ and $T \not\subseteq S$. If $S \subseteq T$, then:
\begin{center}
$x_S + x_T - x_{S\cup T} - x_{S\cap T} = x_S + x_T - x_T - x_S = 0$
\end{center}
and so the constraint becomes trivial. The same argument holds for $T \subseteq S$ by simply switching the variable labels.
\item The final constraint I attempted to simplify was the:
\begin{center}
$x_{\{v\}} \leq 1 \quad \forall v \in V$
\end{center}
constraint. After lots of experimentation, I believe that the inequality in this constraint can be replaced with an equality. This intuition is backed up by the proof that this modification holds in the Fractional Clique Cover Number linear program. Furthermore, when testing my program with the constraint as an inequality, SoPlex reported that there were a small number of redundant constraints, which I believe to relate to this constraint. However, as I could not come up with a formal proof to back up this intuition, I decided to leave the constraint as an inequality in my final implementation. 
\end{itemize}

\section{Examples}
In Figure 3, the outputs for the complete eight vertex graph and Graph 1 are shown. As expected, the Fractional Clique Cover Number of the complete graph is $1$, the Shannon Entropy of the complete graph is $8 - 1 = 7$, the Fractional Clique Cover Number of Graph 1 is $10/3$, and finally the Shannon Entropy of Graph 1 is $11/3$. Please note that multiple other example graphs are included in the /graphs folder, including all 6 graphs from the paper\cite{Max}.

\section{Additional Information}
\begin{itemize}
\item If you would like the program to print out the linear program (the objective function and the constraints) before it is solved, please uncomment out line 435 of \textit{Assignment.py}.
\item I inverted all of the greater than constraints so that the model only consists of equality and less than constraints, in order to simplify the implementation.
\item The vertex numbering in the input files must begin at vertex \textbf{0}, and continue sequentially. 
\item In my initial implementation, I used the linear program solver included in the SciPy package, and then used the Fraction module to convert the floating point output to a rational format. However, this seemed unsatisfactory and susceptible to floating-point arithmetic nuances, and so I reimplemented my code using Pyomo and SoPlex. My program first generates all the variables and constraints, which are then passed to Pyomo. Pyomo builds the LP model and outputs it in the standard \textit{.mps} format, and then my program spawns a new process and executes the SoPlex program, which solves the model. My program then reads the exact solution outputted by SoPlex, parses the rational numbers as strings, creates exact fractions from these strings using the Fraction module, and then finds the exact optimal value using the exact optimal solution and the objective function. 

\end{itemize}
\begin{thebibliography}{999}

\bibitem{Article}
  Peter Cameron:
  \emph{Guessing Numbers of Graphs},
  \\https://cameroncounts.wordpress.com/2016/03/20/guessing-numbers-of-graphs/

\bibitem{Paper}
  Peter Cameron, Anh N. Dang, S\o ren Riis:
  \emph{Guessing Games on Triangle-free Graphs},
  \\The Electronic Journal of Combinatorics
  
 \bibitem{Max}
 Maximilien Gadouleau:
 \emph{On the possible values of the entropy of undirected graphs},
\\Journal of Graph Theory

\end{thebibliography}

\end{document}



what mean by sequencer?
















